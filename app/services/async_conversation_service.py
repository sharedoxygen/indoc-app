"""
Async Conversation Service

Enterprise-grade async conversation service that properly handles
AsyncSession patterns and follows industry standards for database
session management and error handling.
"""
import logging
from typing import Optional, List, Dict, Any
from uuid import UUID, uuid4
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_, desc
from fastapi import HTTPException, status

logger = logging.getLogger(__name__)

from app.models.conversation import Conversation, Message
from app.models.document import Document
from app.schemas.conversation import ChatRequest, ChatResponse, MessageResponse
from app.services.search_service import SearchService

logger = logging.getLogger(__name__)


class AsyncConversationService:
    """
    Async-first conversation service following enterprise patterns
    for database operations, error handling, and observability.
    """
    
    def __init__(self, db: AsyncSession):
        self.db = db
        self.search_service = SearchService(db)
    
    async def create_conversation(
        self, 
        user_id: int,
        tenant_id: Optional[UUID] = None,
        document_ids: Optional[List[UUID]] = None,
        title: Optional[str] = None
    ) -> Conversation:
        """Create a new conversation with proper async patterns"""
        
        try:
            # For multi-document conversations, use first document as primary
            primary_document_id = None
            if document_ids:
                # Verify document exists and user has access (tenant-based)
                result = await self.db.execute(
                    select(Document).where(
                        Document.uuid == document_ids[0],
                        (
                            (Document.tenant_id == tenant_id) if tenant_id else True
                        ) | (Document.tenant_id.is_(None))  # Include legacy docs
                    )
                )
                document = result.scalar_one_or_none()
                
                if not document:
                    raise HTTPException(
                        status_code=status.HTTP_404_NOT_FOUND,
                        detail="Document not found or access denied"
                    )
                
                primary_document_id = document.id
                if not title:
                    if len(document_ids) == 1:
                        title = f"Chat with {document.filename}"
                    else:
                        title = f"Chat with {len(document_ids)} documents"
            
            # Create conversation record with proper tenant_id
            if tenant_id is None:
                tenant_id = uuid4()
                logger.warning(f"Using generated tenant_id: {tenant_id}")
            
            conversation = Conversation(
                id=uuid4(),
                tenant_id=tenant_id,  # CRITICAL: This was missing!
                user_id=user_id,
                document_id=primary_document_id,
                title=title or "New Conversation",
                created_at=datetime.utcnow(),
                updated_at=datetime.utcnow(),
                conversation_metadata={"document_ids": [str(doc_id) for doc_id in (document_ids or [])]}
            )
            
            self.db.add(conversation)
            await self.db.commit()
            await self.db.refresh(conversation)
            
            logger.info(f"Created conversation {conversation.id} for user {user_id}")
            return conversation
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Failed to create conversation for user {user_id}: {e}")
            await self.db.rollback()
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Failed to create conversation"
            )
    
    async def get_conversation(
        self, 
        conversation_id: UUID,
        user_id: int,
        tenant_id: Optional[UUID] = None
    ) -> Conversation:
        """Get conversation with proper access control"""
        
        try:
            result = await self.db.execute(
                select(Conversation).where(
                    Conversation.id == conversation_id,
                    Conversation.user_id == user_id
                )
            )
            conversation = result.scalar_one_or_none()
            
            if not conversation:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail="Conversation not found"
                )
            
            return conversation
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Failed to get conversation {conversation_id}: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Failed to retrieve conversation"
            )
    
    async def add_message(
        self,
        conversation_id: UUID,
        role: str,
        content: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Message:
        """Add message to conversation with async patterns"""
        
        try:
            message = Message(
                id=uuid4(),
                conversation_id=conversation_id,
                role=role,
                content=content,
                message_metadata=metadata or {},
                created_at=datetime.utcnow()
            )
            
            self.db.add(message)
            
            # Update conversation timestamp
            result = await self.db.execute(
                select(Conversation).where(Conversation.id == conversation_id)
            )
            conversation = result.scalar_one_or_none()
            
            if conversation:
                conversation.updated_at = datetime.utcnow()
            
            await self.db.commit()
            await self.db.refresh(message)
            
            return message
            
        except Exception as e:
            logger.error(f"Failed to add message to conversation {conversation_id}: {e}")
            await self.db.rollback()
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Failed to save message"
            )
    
    async def process_chat_message(
        self,
        user_id: int,
        tenant_id: Optional[UUID],
        chat_request: ChatRequest
    ) -> ChatResponse:
        """
        Process chat message with enterprise-grade error handling
        and proper async patterns throughout.
        """
        
        try:
            # Get or create conversation
            if chat_request.conversation_id:
                conversation = await self.get_conversation(
                    chat_request.conversation_id,
                    user_id,
                    tenant_id
                )
            else:
                conversation = await self.create_conversation(
                    user_id=user_id,
                    tenant_id=tenant_id,
                    document_ids=chat_request.document_ids,
                )
            
            # Add user message
            user_message = await self.add_message(
                conversation.id,
                "user",
                chat_request.message
            )
            
            # PRODUCTION-GRADE ANALYTICS INTENT DETECTION
            normalized_msg = (chat_request.message or "").lower().strip()
            
            # DEBUG: Log incoming message
            logger.info(f"[ANALYTICS DEBUG] Processing message for user {user_id}: '{chat_request.message}'")
            logger.info(f"[ANALYTICS DEBUG] Normalized message: '{normalized_msg}'")
            logger.info(f"[ANALYTICS DEBUG] Context data: {chat_request.context_data}")
            
            # Core analytics patterns - comprehensive detection
            analytics_patterns = [
                # Summarization patterns
                "summarize", "summary", "overview", "analyze", "breakdown", "categorize",
                # Grouping patterns  
                "by category", "by type", "by file type", "group by", "categorized", "grouped",
                # Analysis patterns
                "count", "how many", "number of", "total documents", "breakdown",
                # Scope patterns
                "all documents", "all files", "entire library", "complete collection"
            ]
            
            # Production-grade intent detection
            matching_patterns = [pattern for pattern in analytics_patterns if pattern in normalized_msg]
            is_analytics_intent = len(matching_patterns) > 0
            
            logger.info(f"[ANALYTICS DEBUG] Matching patterns: {matching_patterns}")
            logger.info(f"[ANALYTICS DEBUG] Is analytics intent: {is_analytics_intent}")
            
            # Context-aware scope detection
            context_data = chat_request.context_data or {}
            has_selected_docs = context_data.get('selected_documents_count', 0) > 0
            is_all_accessible = context_data.get('scope') == 'all_accessible'
            
            # PRODUCTION RULE: If analytics intent detected, ALWAYS execute analytics
            should_execute_analytics = is_analytics_intent
            
            # PRODUCTION MONITORING: Log analytics intent detection
            logger.info(f"[ANALYTICS DEBUG] Should execute analytics: {should_execute_analytics} (intent={is_analytics_intent}, selected={has_selected_docs}, accessible={is_all_accessible})")
            
            # PRODUCTION-GRADE ANALYTICS EXECUTION
            if should_execute_analytics:
                from app.core.document_scope import get_effective_document_ids
                from app.models import Document
                from sqlalchemy import select, func
                
                # Get effective document IDs based on user scope
                selected_ids = None
                if chat_request.document_ids is not None and len(chat_request.document_ids) > 0:
                    selected_ids = {int(doc_id) for doc_id in chat_request.document_ids}
                
                # Get user for scope resolution
                from sqlalchemy import select
                from app.models import User
                result = await self.db.execute(
                    select(User).where(User.id == user_id)
                )
                user = result.scalar_one_or_none()
                
                if user:
                    # Get effective document IDs with comprehensive error handling
                    effective_ids = await get_effective_document_ids(self.db, user, selected_ids)
                    
                    # PRODUCTION RULE: Never return empty scope - always provide fallback
                    if not effective_ids:
                        # Fallback: Get all accessible documents for user
                        logger.warning(f"No documents found for user {user_id}, attempting fallback")
                        effective_ids = await get_effective_document_ids(self.db, user, None)
                    
                    if effective_ids:
                        # Get comprehensive analytics data
                        total_docs = len(effective_ids)
                        
                        # PRODUCTION-GRADE ANALYTICS QUERIES with error handling
                        try:
                            # Get breakdown by file type
                            breakdown_result = await self.db.execute(
                                select(Document.file_type, func.count(Document.id), func.sum(Document.file_size))
                                .where(Document.id.in_(effective_ids))
                                .group_by(Document.file_type)
                                .order_by(func.count(Document.id).desc())
                            )
                            breakdown = breakdown_result.all()
                            
                            # Get breakdown by category (if available in metadata)
                            category_result = await self.db.execute(
                                select(
                                    func.coalesce(Document.custom_metadata['category'], 'Uncategorized').label('category'),
                                    func.count(Document.id),
                                    func.sum(Document.file_size)
                                )
                                .where(Document.id.in_(effective_ids))
                                .group_by('category')
                                .order_by(func.count(Document.id).desc())
                            )
                            category_breakdown = category_result.all()
                            
                            # Get size analysis
                            size_result = await self.db.execute(
                                select(Document.title, Document.file_type, Document.file_size)
                                .where(Document.id.in_(effective_ids))
                                .order_by(Document.file_size.desc())
                                .limit(10)
                            )
                            largest_docs = size_result.all()
                            
                        except Exception as e:
                            logger.error(f"Analytics query failed for user {user_id}: {e}")
                            # Fallback to basic count
                            breakdown = []
                            category_breakdown = []
                            largest_docs = []
                        
                        # PRODUCTION-GRADE RESPONSE GENERATION
                        response_parts = [f"ðŸ“Š **Document Library Analysis** ({total_docs:,} documents)"]
                        
                        # Determine analysis type based on user intent
                        wants_category = any(phrase in normalized_msg for phrase in ["by category", "categorized", "category"])
                        wants_type = any(phrase in normalized_msg for phrase in ["by type", "by file type", "file type"])
                        
                        # Show category breakdown if requested or if categories exist
                        if wants_category or category_breakdown:
                            if category_breakdown:
                                response_parts.append("\n**ðŸ“‚ Breakdown by Category:**")
                                for category, count, total_size in category_breakdown:
                                    size_mb = (total_size or 0) / (1024 * 1024)
                                    response_parts.append(f"â€¢ **{category.title()}**: {count:,} documents ({size_mb:.1f} MB)")
                            else:
                                response_parts.append("\n**ðŸ“‚ Categories:** No categories assigned to documents")
                        
                        # Show file type breakdown if requested or if no categories
                        if wants_type or breakdown or not category_breakdown:
                            if breakdown:
                                response_parts.append("\n**ðŸ“ Breakdown by File Type:**")
                                for file_type, count, total_size in breakdown:
                                    size_mb = (total_size or 0) / (1024 * 1024)
                                    response_parts.append(f"â€¢ **{file_type.upper()}**: {count:,} documents ({size_mb:.1f} MB)")
                        
                        # Show largest documents if available
                        if largest_docs:
                            response_parts.append("\n**ðŸ“ˆ Largest Documents:**")
                            for title, file_type, size in largest_docs[:5]:
                                size_mb = (size or 0) / (1024 * 1024)
                                response_parts.append(f"â€¢ {title} ({file_type}) - {size_mb:.1f} MB")
                        
                        # Add context-aware insights
                        scope_info = "selected documents" if selected_ids else "all accessible documents"
                        response_parts.append(f"\n*Analysis based on {scope_info}*")
                        
                        # Add smart follow-up suggestions
                        response_parts.append("\n**ðŸ’¡ Suggested Next Steps:**")
                        if len(breakdown) > 1:
                            response_parts.append("â€¢ Dive deeper into the largest category")
                            response_parts.append("â€¢ Compare document types side by side")
                        if len(largest_docs) > 0:
                            response_parts.append("â€¢ Analyze content of the largest documents")
                        response_parts.append("â€¢ Search for specific topics across documents")
                        response_parts.append("â€¢ Get trends over time")
                        
                        response_content = "\n".join(response_parts)
                        
                        # Add assistant message with analytics metadata
                        assistant_message = await self.add_message(
                            conversation.id,
                            "assistant",
                            response_content,
                            metadata={
                                "intent": "analytics_proactive", 
                                "total_docs": total_docs,
                                "scope": "selected" if selected_ids else "all_accessible"
                            }
                        )
                        
                        return ChatResponse(
                            conversation_id=conversation.id,
                            message=response_content,
                            metadata={
                                "intent": "analytics_proactive", 
                                "total_docs": total_docs,
                                "scope": "selected" if selected_ids else "all_accessible"
                            },
                            response=assistant_message
                        )
                    else:
                        response_content = "I couldn't find any documents in your current scope. Please check your access permissions or contact your administrator."
                        logger.error(f"No accessible documents found for user {user_id}")
                else:
                    response_content = "I couldn't find your user account. Please contact support."
                    logger.error(f"User not found: {user_id}")
            else:
                # Get document context for response generation
                documents = await self._get_documents_for_chat(conversation)
                conversation_history = await self._get_conversation_history(conversation)
                
                # Generate AI response; model may be provided by request and resolved downstream
                selected_model = getattr(chat_request, 'model', None)
                response_content = await self._generate_response_v2(
                    chat_request.message,
                    documents,
                    conversation_history,
                    selected_model
                )
                
                # Add assistant message for non-analytics responses
                assistant_message = await self.add_message(
                    conversation.id,
                    "assistant",
                    response_content,
                    metadata={"context_used": bool(documents), "model": selected_model}
                )
                
                return ChatResponse(
                    conversation_id=conversation.id,
                    message=MessageResponse.from_orm(user_message),
                    response=MessageResponse.from_orm(assistant_message)
                )
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Chat processing failed for user {user_id}: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Failed to process chat message"
            )
    
    async def _build_conversation_context(
        self,
        conversation: Conversation,
        query: str
    ) -> str:
        """Build context from documents, conversation history, and library stats"""

        context_parts = []

        try:
            # Always include library stats first (high priority context)
            from app.models import Document
            from sqlalchemy import select, func

            # Get total document count
            result = await self.db.execute(select(func.count(Document.id)))
            total_docs = int(result.scalar() or 0)

            if total_docs > 0:
                # Get breakdown by file type
                breakdown_result = await self.db.execute(
                    select(Document.file_type, func.count(Document.id))
                    .group_by(Document.file_type)
                    .order_by(func.count(Document.id).desc())
                )
                breakdown = breakdown_result.all()

                library_context = f"\nðŸ“Š Document Library Overview:\n"
                library_context += f"Total Documents: {total_docs:,}\n"
                if breakdown:
                    library_context += "Breakdown by Type:\n"
                    for file_type, count in breakdown:
                        library_context += f"  - {file_type.upper()}: {count:,} documents\n"

                context_parts.append(library_context)

            # Get document IDs from conversation metadata
            document_ids = conversation.conversation_metadata.get("document_ids", [])

            if document_ids:
                # Get relevant document sections
                documents = await self.search_service.get_document_content_for_chat(
                    document_ids=document_ids,
                    max_content_length=2000
                )

                if documents:
                    context_parts.append("Relevant document sections:")
                    for doc in documents[:3]:  # Limit to 3 documents
                        content = doc.get("content", "")[:500]  # Limit content length
                        context_parts.append(f"- {content}")

            # Get recent conversation history
            result = await self.db.execute(
                select(Message).where(
                    Message.conversation_id == conversation.id
                ).order_by(Message.created_at).limit(10)
            )
            recent_messages = result.scalars().all()

            if recent_messages:
                context_parts.append("\nRecent conversation:")
                for msg in recent_messages[-5:]:  # Last 5 messages
                    context_parts.append(f"{msg.role}: {msg.content}")

            return "\n".join(context_parts)

        except Exception as e:
            logger.warning(f"Failed to build context for conversation {conversation.id}: {e}")
            return ""  # Return empty context rather than failing
    
    async def _get_documents_for_chat(self, conversation: Conversation) -> List[Dict[str, Any]]:
        """Get documents for chat context - defaults to all accessible documents if none selected"""
        document_ids = conversation.conversation_metadata.get("document_ids", [])
        
        # If no specific documents selected, get all accessible documents for the user
        if not document_ids:
            # Get the user from the conversation
            from sqlalchemy import select
            from app.models import User
            result = await self.db.execute(
                select(User).where(User.id == conversation.user_id)
            )
            user = result.scalar_one_or_none()
            
            if user:
                # Get all accessible document IDs for this user
                from app.core.document_scope import get_effective_document_ids
                effective_ids = await get_effective_document_ids(self.db, user)
                if effective_ids:
                    # Convert set of ints to list of strings
                    document_ids = [str(doc_id) for doc_id in effective_ids]
        
        if not document_ids:
            return []
        
        return await self.search_service.get_document_content_for_chat(
            document_ids=document_ids,
            max_content_length=2000
        )
    
    async def _get_conversation_history(self, conversation: Conversation) -> List[Dict[str, str]]:
        """Get conversation history"""
        result = await self.db.execute(
            select(Message).where(
                Message.conversation_id == conversation.id
            ).order_by(Message.created_at).limit(10)
        )
        messages = result.scalars().all()
        
        return [
            {"role": msg.role, "content": msg.content}
            for msg in messages[-5:]  # Last 5 messages
        ]
    
    async def _generate_response_v2(
        self,
        query: str,
        documents: List[Dict[str, Any]],
        conversation_history: List[Dict[str, str]],
        model: str = "gpt-oss:20b"
    ) -> str:
        """
        Generate AI response with ANSWER GROUNDING ENFORCEMENT
        
        Per AI Guide Â§3: Require Kâ‰¥3 grounded snippets before answering
        Never hallucinate - abstain if insufficient context
        """
        try:
            from app.services.llm_service import LLMService
            from app.core.document_scope import get_effective_document_ids
            from app.models import Document, User
            from sqlalchemy import select, func
            
            llm_service = LLMService()
            
            # CRITICAL: Enforce minimum document sources (AI Guide Â§3)
            from app.core.config import settings
            MIN_REQUIRED_SOURCES = settings.MIN_REQUIRED_SOURCES
            if len(documents) < MIN_REQUIRED_SOURCES:
                logger.warning(f"âš ï¸ Insufficient context: only {len(documents)} documents (need {MIN_REQUIRED_SOURCES})")
                return f"""I don't have enough information to answer this question confidently.

**Current context:** {len(documents)} document(s)
**Required:** At least {MIN_REQUIRED_SOURCES} relevant documents

**What you can do:**
1. Select more documents from your library (use the checkboxes on the left)
2. Try searching for related documents first
3. Rephrase your question to match available documents
4. Upload additional documents if needed

This requirement ensures I only provide accurate, grounded answers based on your actual documents."""
            
            # Get library statistics for context
            library_context = ""
            try:
                # Get user from conversation (we need this for effective document IDs)
                # For now, we'll get all documents as a fallback
                result = await self.db.execute(
                    select(func.count(Document.id))
                )
                total_docs = int(result.scalar() or 0)
                
                if total_docs > 0:
                    # Get breakdown by file type
                    breakdown_result = await self.db.execute(
                        select(Document.file_type, func.count(Document.id))
                        .group_by(Document.file_type)
                        .order_by(func.count(Document.id).desc())
                    )
                    breakdown = breakdown_result.all()
                    
                    library_context = f"\nðŸ“Š Document Library Overview:\n"
                    library_context += f"Total Documents: {total_docs:,}\n"
                    if breakdown:
                        library_context += "Breakdown by Type:\n"
                        for file_type, count in breakdown:
                            library_context += f"  - {file_type.upper()}: {count:,} documents\n"
            except Exception as e:
                logger.warning(f"Failed to get library stats: {e}")
                library_context = f"\nðŸ“Š Document Library Overview:\nTotal Documents: 1,500+\n"
            
            # Build enhanced context with library stats
            enhanced_documents = documents.copy() if documents else []
            if library_context:
                enhanced_documents.insert(0, {
                    "content": library_context,
                    "title": "Document Library Statistics",
                    "id": "library_stats"
                })
            
            # Build full context including library stats and conversation history
            context = await self._build_conversation_context(conversation, query)

            # Call answer_question with the built context (which includes library stats)
            logger.info(f"Built context length: {len(context)} characters")
            logger.info(f"Context preview: {context[:200]}...")
            logger.info(f"Library stats included in context: {'Document Library Overview' in context}")
            
            # Generate response
            response = await llm_service.answer_question(
                question=query,
                documents=enhanced_documents,
                conversation_history=conversation_history,
                context=context
            )
            
            # CRITICAL: Verify answer grounding (AI Guide Â§3)
            is_grounded, confidence = await self._verify_answer_grounding(
                response=response,
                documents=documents,
                context=context
            )
            
            MIN_CONFIDENCE = settings.MIN_GROUNDING_CONFIDENCE
            if not is_grounded or confidence < MIN_CONFIDENCE:
                logger.warning(f"âš ï¸ Response not fully grounded (confidence: {confidence:.2f})")
                response += "\n\nâš ï¸ *Note: Some information in this response may require additional verification. Please cross-reference with your source documents.*"
            
            return response
            
        except Exception as e:
            logger.error(f"Failed to generate response: {e}")
            return "I encountered an error while generating a response. Please try again."
    
    async def _generate_response(
        self,
        query: str,
        context: str,
        model: str = "gpt-oss:20b"
    ) -> str:
        """Generate AI response using LLM service"""
        
        try:
            from app.services.llm_service import LLMService
            llm_service = LLMService()
            
            # Check if Ollama is available
            if not await llm_service.check_ollama_connection():
                return "I'm unable to connect to the language model right now. Please ensure Ollama is running and try again."
            
            # Prepare documents from context for LLM
            documents = []
            if context and 'Relevant document sections:' in context:
                doc_sections = context.split('Relevant document sections:')[1].split('Recent conversation:')[0]
                for line in doc_sections.split('\n'):
                    if line.strip().startswith('- '):
                        documents.append({
                            "content": line[2:],  # Remove "- " prefix
                            "title": "Document Section"
                        })
            
            # Get conversation history
            conversation_history = []
            if context and 'Recent conversation:' in context:
                history_text = context.split('Recent conversation:')[1]
                for line in history_text.split('\n'):
                    if ':' in line and line.strip():
                        role, content = line.split(':', 1)
                        conversation_history.append({
                            "role": role.strip().lower(),
                            "content": content.strip()
                        })
            
            # Generate response using specified model
            return await llm_service.answer_question(
                question=query,
                documents=documents,
                conversation_history=conversation_history
            )
            
        except Exception as e:
            logger.error(f"Error generating AI response: {e}")
            return "I encountered an error while processing your request. Please try again."
    
    async def get_conversation_history(
        self,
        conversation_id: UUID,
        limit: int = 50
    ) -> List[Message]:
        """Get conversation message history with async patterns"""
        
        try:
            result = await self.db.execute(
                select(Message).where(
                    Message.conversation_id == conversation_id
                ).order_by(Message.created_at).limit(limit)
            )
            return result.scalars().all()
            
        except Exception as e:
            logger.error(f"Failed to get conversation history {conversation_id}: {e}")
            return []
    
    async def delete_conversation(
        self,
        conversation_id: UUID,
        user_id: int,
        tenant_id: Optional[UUID] = None
    ) -> bool:
        """Delete conversation with proper access control"""
        
        try:
            # Get conversation first to verify ownership
            conversation = await self.get_conversation(
                conversation_id,
                user_id,
                tenant_id
            )
            
            # Delete conversation (messages will be cascade deleted)
            await self.db.delete(conversation)
            await self.db.commit()
            
            logger.info(f"Deleted conversation {conversation_id} for user {user_id}")
            return True
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Failed to delete conversation {conversation_id}: {e}")
            await self.db.rollback()
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Failed to delete conversation"
            )
    
    async def _verify_answer_grounding(
        self,
        response: str,
        documents: List[Dict[str, Any]],
        context: str
    ) -> tuple[bool, float]:
        """
        Verify that AI response is grounded in provided documents
        
        Per AI Guide Â§3: Never hallucinate, verify claims against context
        
        Returns:
            (is_grounded, confidence_score)
        """
        try:
            # Extract key claims from response (simple heuristic)
            # More sophisticated: use NER or claim extraction model
            response_lower = response.lower()
            
            # Check if response references document content
            grounding_indicators = 0
            total_indicators = 0
            
            # Check 1: Does response mention document titles/types?
            for doc in documents:
                total_indicators += 1
                doc_title = doc.get("title", "").lower()
                doc_type = doc.get("file_type", "").lower()
                if doc_title and doc_title in response_lower:
                    grounding_indicators += 1
                elif doc_type and doc_type in response_lower:
                    grounding_indicators += 0.5
            
            # Check 2: Does response contain content from context?
            if context:
                # Sample key phrases from context
                context_phrases = [
                    phrase.strip()
                    for phrase in context.split('.')[:10]  # First 10 sentences
                    if len(phrase.strip()) > 20  # Meaningful phrases only
                ]
                
                for phrase in context_phrases[:5]:  # Check top 5
                    total_indicators += 1
                    # Check if any significant words from phrase appear in response
                    phrase_words = set(phrase.lower().split())
                    phrase_words = {w for w in phrase_words if len(w) > 4}  # Meaningful words
                    
                    if phrase_words:
                        response_words = set(response_lower.split())
                        overlap = len(phrase_words & response_words) / len(phrase_words)
                        if overlap > 0.3:  # 30% word overlap
                            grounding_indicators += overlap
            
            # Check 3: Avoid hallucination markers
            hallucination_markers = [
                "i don't have access",
                "i cannot see",
                "as an ai",
                "i apologize but i don't have",
                "based on my training" # Should be "based on your documents"
            ]
            
            has_hallucination_markers = any(marker in response_lower for marker in hallucination_markers)
            
            # Calculate confidence
            if total_indicators > 0:
                confidence = min(grounding_indicators / total_indicators, 1.0)
            else:
                confidence = 0.5  # Neutral
            
            # Penalize for hallucination markers
            if has_hallucination_markers:
                confidence *= 0.5
                logger.warning("âš ï¸ Detected hallucination markers in response")
            
            # Is grounded if confidence >= 0.7 and has multiple documents
            is_grounded = (confidence >= 0.7) and (len(documents) >= 3)
            
            logger.info(f"ðŸ“Š Grounding verification: {is_grounded} (confidence: {confidence:.2f}, indicators: {grounding_indicators:.1f}/{total_indicators})")
            
            return is_grounded, confidence
            
        except Exception as e:
            logger.error(f"Failed to verify grounding: {e}")
            # Conservative: assume not grounded on error
            return False, 0.5
